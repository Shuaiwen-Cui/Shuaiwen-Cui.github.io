## __TRANSFORMER__

## __入门__

<div class="grid cards" markdown>

-   :material-file:{ .lg .middle } __Attention is all you need 论文__ 

    ---


    [:octicons-arrow-right-24: <a href="https://arxiv.org/abs/1706.03762" target="_blank"> 传送门 </a>](#)

-   :material-youtube:{ .lg .middle } __Attention is all you need 解读✅__ 

    ---


    [:octicons-arrow-right-24: <a href="https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.1387.collection.video_card.click&vd_source=5a427660f0337fedc22d4803661d493f" target="_blank"> 传送门 </a>](#)

</div>

## __深入__

<div class="grid cards" markdown>

-   :fontawesome-brands-bilibili:{ .lg .middle } __超强动画，一步一步深入浅出解释Transformer原理！🏆__ 

    ---

    讲得很好！

    [:octicons-arrow-right-24: <a href="https://www.youtube.com/watch?v=4Bdc55j80l8" target="_blank"> 传送门 </a>](#)

-   :fontawesome-brands-bilibili:{ .lg .middle } __Attention is all you need 解读 (中文)__ 

    ---
    并不很严谨，但是有助于感性认知。

    [:octicons-arrow-right-24: <a href="https://www.bilibili.com/video/BV14m421u7EM/?spm_id_from=333.337.search-card.all.click&vd_source=5a427660f0337fedc22d4803661d493f" target="_blank"> 传送门 </a>](#)

-   :fontawesome-brands-bilibili:{ .lg .middle } __注意力机制的本质|Self-Attention|Transformer|QKV矩阵__ 

    ---

    [:octicons-arrow-right-24: <a href="https://www.bilibili.com/video/BV1dt4y1J7ov/?spm_id_from=333.788.recommend_more_video.0&vd_source=5a427660f0337fedc22d4803661d493f" target="_blank"> 传送门 </a>](#)

</div>

## __实践__

<div class="grid cards" markdown>

-   :material-file:{ .lg .middle } __annotated-transformer__ 

    ---


    [:octicons-arrow-right-24: <a href="http://nlp.seas.harvard.edu/annotated-transformer" target="_blank"> 笔记 </a>](#)

    [:octicons-arrow-right-24: <a href="https://github.com/harvardnlp/annotated-transformer" target="_blank"> 代码 </a>](#)

-   :material-file:{ .lg .middle } __transformer tutorial🎯🏆__ 

    ---

    [:octicons-arrow-right-24: <a href="https://medium.com/towards-data-science/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021" target="_blank"> 理论 1 </a>](#)

    [:octicons-arrow-right-24: <a href="https://medium.com/towards-data-science/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-2-bf2403804ada" target="_blank"> 理论 2 </a>](#)

    [:octicons-arrow-right-24: <a href="https://medium.com/towards-data-science/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb" target="_blank"> 实战教程 </a>](#)

</div>